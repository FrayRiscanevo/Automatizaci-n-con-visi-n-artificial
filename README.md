üìå Descripci√≥n del proyecto

Este proyecto implementa un sistema de automatizaci√≥n rob√≥tica con visi√≥n artificial en lazo cerrado, donde un manipulador industrial ABB ajusta din√°micamente su posici√≥n a partir de informaci√≥n visual obtenida en tiempo real. La soluci√≥n integra Python, OpenCV, marcadores ArUco y programaci√≥n RAPID, permitiendo que el robot reaccione autom√°ticamente a la posici√≥n y orientaci√≥n de un objeto detectado por una c√°mara.

El sistema fue desarrollado y validado en un entorno de simulaci√≥n utilizando ABB RobotStudio con controlador IRC5, estableciendo una comunicaci√≥n TCP/IP tipo socket entre el PC y el robot. A trav√©s de esta arquitectura, las coordenadas calculadas desde visi√≥n artificial (X, Y, Z) son enviadas al controlador ABB, donde se actualizan los robtargets y se ejecuta el movimiento del robot de forma autom√°tica.

‚öôÔ∏è Arquitectura general

El proyecto est√° estructurado en tres bloques principales:

PC (Python + OpenCV):
Captura de im√°genes, detecci√≥n de marcadores ArUco, c√°lculo de posici√≥n y orientaci√≥n (tvec, rvec) y l√≥gica de control.

Comunicaci√≥n TCP/IP (Sockets):
Env√≠o de datos de posici√≥n desde Python hacia el robot mediante una arquitectura cliente-servidor.

Robot ABB (RAPID / RobotStudio):
Recepci√≥n de coordenadas, c√°lculo de offsets, actualizaci√≥n de targets y ejecuci√≥n del movimiento del TCP hacia la posici√≥n detectada.

Esta arquitectura permite una integraci√≥n flexible entre visi√≥n artificial y control rob√≥tico, simulando un entorno industrial real.

üîÑ Flujo de funcionamiento

Captura:
La c√°mara adquiere una imagen del entorno donde se encuentra el objeto con marcador ArUco.

Procesamiento:
OpenCV detecta el marcador y calcula su pose (posici√≥n y orientaci√≥n).

Env√≠o de datos:
Python formatea las coordenadas y las env√≠a al robot mediante un socket TCP/IP.

Alineaci√≥n y movimiento:
El robot recibe los datos, calcula el offset necesario y mueve su TCP a la posici√≥n objetivo.

üß™ Metodolog√≠a y pruebas realizadas

El desarrollo se realiz√≥ de forma incremental:

Verificaci√≥n del funcionamiento de la c√°mara y detecci√≥n de distancia y pose.

Pruebas de comunicaci√≥n enviando datos de prueba desde Python al robot.

Creaci√≥n y validaci√≥n de un programa RAPID para movimientos manuales.

Integraci√≥n total del sistema, logrando movimiento autom√°tico del robot a partir de la informaci√≥n visual.

‚ö†Ô∏è Desaf√≠os abordados

Calibraci√≥n precisa de la c√°mara para reducir errores de distorsi√≥n.

Latencia en la comunicaci√≥n TCP/IP, que puede afectar el tiempo de respuesta.

Condiciones de iluminaci√≥n y reflejos, que influyen en la detecci√≥n confiable de los marcadores ArUco.

üöÄ Aplicaciones potenciales

Automatizaci√≥n con cobots para manipulaci√≥n de objetos.

Sistemas de seguimiento visual con c√°mara en tiempo real.

Ensamble y montaje de componentes con alta precisi√≥n.

Inspecci√≥n visual industrial y control de calidad.

‚úÖ Conclusi√≥n

El proyecto demuestra la viabilidad de integrar visi√≥n artificial y control rob√≥tico para lograr sistemas de automatizaci√≥n m√°s precisos, adaptables y eficientes. La combinaci√≥n de Python, OpenCV y RobotStudio permite reducir tiempos de configuraci√≥n, mejorar la exactitud del movimiento y sentar bases para aplicaciones industriales m√°s avanzadas.
